{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lbr\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES = ['Electronic', 'Experimental', 'Folk', 'HipHop', 'Instrumental', 'International', 'Pop','Rock']\n",
    "WINDOW_SIZE = 2048\n",
    "WINDOW_STRIDE = WINDOW_SIZE // 2\n",
    "N_MELS = 128\n",
    "MEL_KWARGS = {\n",
    "    'n_fft': WINDOW_SIZE,\n",
    "    'hop_length': WINDOW_STRIDE,\n",
    "    'n_mels': N_MELS\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_output_function(model, layer_name):\n",
    "    input = model.get_layer('input').input\n",
    "    output = model.get_layer(layer_name).output\n",
    "    f = K.function([input, K.learning_phase()], [output])\n",
    "    return lambda x: f([x, 0])[0] # learning_phase = 0 means test\n",
    "\n",
    "def load_track(filename, enforce_shape=None):\n",
    "    new_input, sample_rate = lbr.load(filename, mono=True, duration=40.0)\n",
    "    features = lbr.feature.melspectrogram(new_input, **MEL_KWARGS).T\n",
    "\n",
    "    if enforce_shape is not None:\n",
    "        if features.shape[0] < enforce_shape[0]:\n",
    "            delta_shape = (enforce_shape[0] - features.shape[0],\n",
    "                    enforce_shape[1])\n",
    "            features = np.append(features, np.zeros(delta_shape), axis=0)\n",
    "        elif features.shape[0] > enforce_shape[0]:\n",
    "            features = features[: enforce_shape[0], :]\n",
    "\n",
    "    features[features == 0] = 1e-6\n",
    "    return (np.log(features), float(new_input.shape[0]) / sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from pickle import dump\n",
    "import os\n",
    "from optparse import OptionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_COUNT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_shape(dataset_path):\n",
    "    tmp_features, _ = load_track(os.path.join(dataset_path,\n",
    "        'Electronic/Electronic.00000.mp3'))\n",
    "    return tmp_features.shape\n",
    "\n",
    "def collect_data(dataset_path):\n",
    "    '''\n",
    "    :param dataset_path: path to the dataset directory\n",
    "    :returns: triple (x, y, track_paths) where x is a matrix containing\n",
    "        extracted features, y is a one-hot matrix of genre labels and\n",
    "        track_paths is a dict of absolute track paths indexed by row indices in\n",
    "        the x and y matrices\n",
    "    '''\n",
    "    default_shape = get_default_shape(dataset_path)\n",
    "    x = np.zeros((TRACK_COUNT,) + default_shape, dtype=np.float32)\n",
    "    y = np.zeros((TRACK_COUNT, len(GENRES)), dtype=np.float32)\n",
    "    track_paths = {}\n",
    "\n",
    "    for (genre_index, genre_name) in enumerate(GENRES):\n",
    "        for i in range(1000):            \n",
    "            file_name = '{}/{}.{}.mp3'.format(genre_name,\n",
    "                    genre_name, '%05d' % i)\n",
    "#            print('Processing', file_name)\n",
    "            \n",
    "            path = os.path.join(dataset_path, file_name)\n",
    "#            print(genre_index,i)\n",
    "            track_index = genre_index  * 1000 + i\n",
    "            \n",
    "            x[track_index], _ = load_track(path, default_shape)\n",
    "            y[track_index, genre_index] = 1\n",
    "            track_paths[track_index] = os.path.abspath(path)\n",
    "\n",
    "    return (x, y, track_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=os.path.join('/Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/genres')\n",
    "output_pkl_path=os.path.join('/Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/data.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y, track_paths) = collect_data(dataset_path)\n",
    "data = {'x': x, 'y': y, 'track_paths': track_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Writing the Pickle/Data - This fails for files greater than 4GB\n",
    "with open(output_pkl_path, 'wb') as f:\n",
    "    dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the C RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Dropout, Activation, \\\n",
    "        TimeDistributed, Convolution1D, MaxPooling1D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "from optparse import OptionParser\n",
    "from sys import stderr, argv\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_LAYERS = 3\n",
    "FILTER_LENGTH = 5\n",
    "CONV_FILTER_COUNT = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_COUNT = 85\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model_path):\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    (x_train, x_val, y_train, y_val) = train_test_split(x, y, test_size=0.3,\n",
    "            random_state=SEED)\n",
    "\n",
    "    print('Building model...')\n",
    "\n",
    "    n_features = x_train.shape[2]\n",
    "    input_shape = (None, n_features)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "    layer = model_input\n",
    "    for i in range(N_LAYERS):\n",
    "        layer = Convolution1D(\n",
    "                filters=CONV_FILTER_COUNT,\n",
    "                kernel_size=FILTER_LENGTH,\n",
    "                name='convolution_' + str(i + 1)\n",
    "            )(layer)\n",
    "        layer = BatchNormalization(momentum=0.9)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling1D(2)(layer)\n",
    "        layer = Dropout(0.5)(layer)\n",
    "\n",
    "    layer = TimeDistributed(Dense(len(GENRES)))(layer)\n",
    "    time_distributed_merge_layer = Lambda(\n",
    "            function=lambda x: K.mean(x, axis=1), \n",
    "            output_shape=lambda shape: (shape[0],) + shape[2:],\n",
    "            name='output_merged'\n",
    "        )\n",
    "    layer = time_distributed_merge_layer(layer)\n",
    "    layer = Activation('softmax', name='output_realtime')(layer)\n",
    "    model_output = layer\n",
    "    model = Model(model_input, model_output)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    print('Training...')\n",
    "    model.fit(\n",
    "        x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCH_COUNT,\n",
    "        validation_data=(x_val, y_val), verbose=1, callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                model_path, save_best_only=True, monitor='val_acc', verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=os.path.join('/Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5')\n",
    "output_pkl_path=os.path.join('/Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading the Pickle/Data - This fails for files greater than 4GB\n",
    "with open(output_pkl_path, 'rb') as f:\n",
    "      data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Training...\n",
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.3964 - acc: 0.4114\n",
      "Epoch 00001: val_acc improved from -inf to 0.54500, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 91s 13ms/sample - loss: 1.3970 - acc: 0.4117 - val_loss: 1.2483 - val_acc: 0.5450\n",
      "Epoch 2/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.2693 - acc: 0.4802\n",
      "Epoch 00002: val_acc did not improve from 0.54500\n",
      "7000/7000 [==============================] - 95s 14ms/sample - loss: 1.2681 - acc: 0.4799 - val_loss: 1.3144 - val_acc: 0.3180\n",
      "Epoch 3/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.2330 - acc: 0.4791\n",
      "Epoch 00003: val_acc improved from 0.54500 to 0.58033, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 95s 14ms/sample - loss: 1.2322 - acc: 0.4797 - val_loss: 1.2150 - val_acc: 0.5803\n",
      "Epoch 4/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.1854 - acc: 0.5024\n",
      "Epoch 00004: val_acc did not improve from 0.58033\n",
      "7000/7000 [==============================] - 95s 14ms/sample - loss: 1.1847 - acc: 0.5021 - val_loss: 1.1754 - val_acc: 0.3823\n",
      "Epoch 5/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.1496 - acc: 0.5312\n",
      "Epoch 00005: val_acc did not improve from 0.58033\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 1.1499 - acc: 0.5316 - val_loss: 1.2709 - val_acc: 0.5507\n",
      "Epoch 6/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.1326 - acc: 0.4897\n",
      "Epoch 00006: val_acc did not improve from 0.58033\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 1.1325 - acc: 0.4899 - val_loss: 1.0950 - val_acc: 0.4163\n",
      "Epoch 7/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.0964 - acc: 0.5156\n",
      "Epoch 00007: val_acc did not improve from 0.58033\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 1.0967 - acc: 0.5160 - val_loss: 1.2495 - val_acc: 0.3753\n",
      "Epoch 8/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.0849 - acc: 0.4958\n",
      "Epoch 00008: val_acc improved from 0.58033 to 0.59533, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 1.0841 - acc: 0.4964 - val_loss: 1.1763 - val_acc: 0.5953\n",
      "Epoch 9/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.0638 - acc: 0.4705\n",
      "Epoch 00009: val_acc did not improve from 0.59533\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 1.0628 - acc: 0.4701 - val_loss: 1.1157 - val_acc: 0.4157\n",
      "Epoch 10/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.0458 - acc: 0.5023\n",
      "Epoch 00010: val_acc did not improve from 0.59533\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 1.0467 - acc: 0.5017 - val_loss: 1.0620 - val_acc: 0.4303\n",
      "Epoch 11/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.0219 - acc: 0.4993\n",
      "Epoch 00011: val_acc did not improve from 0.59533\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 1.0225 - acc: 0.4996 - val_loss: 1.1123 - val_acc: 0.4033\n",
      "Epoch 12/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 1.0054 - acc: 0.5146\n",
      "Epoch 00012: val_acc did not improve from 0.59533\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 1.0059 - acc: 0.5140 - val_loss: 1.1924 - val_acc: 0.3897\n",
      "Epoch 13/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.9901 - acc: 0.5109\n",
      "Epoch 00013: val_acc did not improve from 0.59533\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.9894 - acc: 0.5113 - val_loss: 1.1170 - val_acc: 0.4220\n",
      "Epoch 14/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.9804 - acc: 0.5652\n",
      "Epoch 00014: val_acc did not improve from 0.59533\n",
      "7000/7000 [==============================] - 104s 15ms/sample - loss: 0.9798 - acc: 0.5660 - val_loss: 1.2398 - val_acc: 0.3747\n",
      "Epoch 15/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.9632 - acc: 0.4954\n",
      "Epoch 00015: val_acc did not improve from 0.59533\n",
      "7000/7000 [==============================] - 107s 15ms/sample - loss: 0.9639 - acc: 0.4953 - val_loss: 1.0423 - val_acc: 0.4403\n",
      "Epoch 16/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.9461 - acc: 0.5186\n",
      "Epoch 00016: val_acc improved from 0.59533 to 0.62467, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 116s 17ms/sample - loss: 0.9466 - acc: 0.5186 - val_loss: 1.0983 - val_acc: 0.6247\n",
      "Epoch 17/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.9195 - acc: 0.5563\n",
      "Epoch 00017: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 104s 15ms/sample - loss: 0.9185 - acc: 0.5560 - val_loss: 1.0790 - val_acc: 0.4440\n",
      "Epoch 18/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.9146 - acc: 0.5122\n",
      "Epoch 00018: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 103s 15ms/sample - loss: 0.9152 - acc: 0.5124 - val_loss: 1.0979 - val_acc: 0.4313\n",
      "Epoch 19/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.9137 - acc: 0.5138\n",
      "Epoch 00019: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.9144 - acc: 0.5141 - val_loss: 1.0852 - val_acc: 0.4230\n",
      "Epoch 20/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.8759 - acc: 0.4993\n",
      "Epoch 00020: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 106s 15ms/sample - loss: 0.8764 - acc: 0.4997 - val_loss: 1.1091 - val_acc: 0.4273\n",
      "Epoch 21/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.8580 - acc: 0.4991\n",
      "Epoch 00021: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.8579 - acc: 0.4997 - val_loss: 1.0205 - val_acc: 0.4513\n",
      "Epoch 22/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.8488 - acc: 0.5474\n",
      "Epoch 00022: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.8492 - acc: 0.5473 - val_loss: 1.0688 - val_acc: 0.4383\n",
      "Epoch 23/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.8372 - acc: 0.5249\n",
      "Epoch 00023: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 102s 15ms/sample - loss: 0.8369 - acc: 0.5249 - val_loss: 1.1032 - val_acc: 0.4243\n",
      "Epoch 24/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.8297 - acc: 0.5254\n",
      "Epoch 00024: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.8307 - acc: 0.5247 - val_loss: 1.0613 - val_acc: 0.4413\n",
      "Epoch 25/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.8176 - acc: 0.5836\n",
      "Epoch 00025: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 97s 14ms/sample - loss: 0.8164 - acc: 0.5837 - val_loss: 1.0941 - val_acc: 0.4400\n",
      "Epoch 26/85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.8110 - acc: 0.5328\n",
      "Epoch 00026: val_acc did not improve from 0.62467\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.8105 - acc: 0.5331 - val_loss: 1.0465 - val_acc: 0.4533\n",
      "Epoch 27/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.7359 - acc: 0.5755\n",
      "Epoch 00027: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 100s 14ms/sample - loss: 0.7362 - acc: 0.5756 - val_loss: 1.0279 - val_acc: 0.4687\n",
      "Epoch 28/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.7083 - acc: 0.6131\n",
      "Epoch 00028: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 100s 14ms/sample - loss: 0.7084 - acc: 0.6129 - val_loss: 1.0071 - val_acc: 0.4707\n",
      "Epoch 29/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6894 - acc: 0.5827\n",
      "Epoch 00029: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 106s 15ms/sample - loss: 0.6890 - acc: 0.5829 - val_loss: 1.0459 - val_acc: 0.4533\n",
      "Epoch 30/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6765 - acc: 0.6171\n",
      "Epoch 00030: val_acc did not improve from 0.62467\n",
      "7000/7000 [==============================] - 104s 15ms/sample - loss: 0.6772 - acc: 0.6174 - val_loss: 1.1174 - val_acc: 0.4553\n",
      "Epoch 31/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6607 - acc: 0.6260\n",
      "Epoch 00031: val_acc improved from 0.62467 to 0.64967, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.6605 - acc: 0.6260 - val_loss: 1.0957 - val_acc: 0.6497\n",
      "Epoch 32/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6523 - acc: 0.6499\n",
      "Epoch 00032: val_acc did not improve from 0.64967\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.6533 - acc: 0.6500 - val_loss: 1.0411 - val_acc: 0.4583\n",
      "Epoch 33/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6370 - acc: 0.6286\n",
      "Epoch 00033: val_acc did not improve from 0.64967\n",
      "7000/7000 [==============================] - 109s 16ms/sample - loss: 0.6376 - acc: 0.6283 - val_loss: 1.1032 - val_acc: 0.4503\n",
      "Epoch 34/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.6422\n",
      "Epoch 00034: val_acc did not improve from 0.64967\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.6275 - acc: 0.6431 - val_loss: 1.0531 - val_acc: 0.6480\n",
      "Epoch 35/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.6657\n",
      "Epoch 00035: val_acc improved from 0.64967 to 0.65000, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 95s 14ms/sample - loss: 0.6097 - acc: 0.6659 - val_loss: 1.1766 - val_acc: 0.6500\n",
      "Epoch 36/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.6010 - acc: 0.6237\n",
      "Epoch 00036: val_acc did not improve from 0.65000\n",
      "7000/7000 [==============================] - 97s 14ms/sample - loss: 0.6016 - acc: 0.6239 - val_loss: 1.1219 - val_acc: 0.4513\n",
      "Epoch 37/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.6531\n",
      "Epoch 00037: val_acc improved from 0.65000 to 0.65033, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 103s 15ms/sample - loss: 0.5896 - acc: 0.6533 - val_loss: 1.1427 - val_acc: 0.6503\n",
      "Epoch 38/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.6704\n",
      "Epoch 00038: val_acc did not improve from 0.65033\n",
      "7000/7000 [==============================] - 107s 15ms/sample - loss: 0.5721 - acc: 0.6704 - val_loss: 1.1783 - val_acc: 0.4337\n",
      "Epoch 39/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.5625 - acc: 0.6638\n",
      "Epoch 00039: val_acc did not improve from 0.65033\n",
      "7000/7000 [==============================] - 103s 15ms/sample - loss: 0.5636 - acc: 0.6634 - val_loss: 1.2451 - val_acc: 0.4410\n",
      "Epoch 40/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.6448\n",
      "Epoch 00040: val_acc did not improve from 0.65033\n",
      "7000/7000 [==============================] - 114s 16ms/sample - loss: 0.5560 - acc: 0.6447 - val_loss: 1.1864 - val_acc: 0.4523\n",
      "Epoch 41/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.5362 - acc: 0.6952\n",
      "Epoch 00041: val_acc did not improve from 0.65033\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.5363 - acc: 0.6949 - val_loss: 1.1419 - val_acc: 0.4680\n",
      "Epoch 42/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4741 - acc: 0.7203\n",
      "Epoch 00042: val_acc improved from 0.65033 to 0.65333, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.4738 - acc: 0.7209 - val_loss: 1.1527 - val_acc: 0.6533\n",
      "Epoch 43/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.7233\n",
      "Epoch 00043: val_acc did not improve from 0.65333\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.4559 - acc: 0.7230 - val_loss: 1.1236 - val_acc: 0.4760\n",
      "Epoch 44/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.6696\n",
      "Epoch 00044: val_acc did not improve from 0.65333\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.4526 - acc: 0.6699 - val_loss: 1.1639 - val_acc: 0.4657\n",
      "Epoch 45/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4436 - acc: 0.6868\n",
      "Epoch 00045: val_acc did not improve from 0.65333\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.4430 - acc: 0.6870 - val_loss: 1.1896 - val_acc: 0.4563\n",
      "Epoch 46/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4342 - acc: 0.6885\n",
      "Epoch 00046: val_acc improved from 0.65333 to 0.66867, saving model to /Users/jairomelo/Desktop/ML/YORK/ML1020/Final Project/model.h5\n",
      "7000/7000 [==============================] - 105s 15ms/sample - loss: 0.4348 - acc: 0.6887 - val_loss: 1.1541 - val_acc: 0.6687\n",
      "Epoch 47/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.6917\n",
      "Epoch 00047: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 103s 15ms/sample - loss: 0.4371 - acc: 0.6917 - val_loss: 1.2222 - val_acc: 0.4583\n",
      "Epoch 48/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.6849\n",
      "Epoch 00048: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.4143 - acc: 0.6857 - val_loss: 1.1828 - val_acc: 0.4697\n",
      "Epoch 49/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.4114 - acc: 0.6925\n",
      "Epoch 00049: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 95s 14ms/sample - loss: 0.4119 - acc: 0.6927 - val_loss: 1.2011 - val_acc: 0.4650\n",
      "Epoch 50/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3939 - acc: 0.6931\n",
      "Epoch 00050: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 94s 13ms/sample - loss: 0.3935 - acc: 0.6927 - val_loss: 1.2321 - val_acc: 0.4597\n",
      "Epoch 51/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.6904\n",
      "Epoch 00051: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 0.3957 - acc: 0.6906 - val_loss: 1.2791 - val_acc: 0.4537\n",
      "Epoch 52/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.7157\n",
      "Epoch 00052: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 111s 16ms/sample - loss: 0.3863 - acc: 0.7159 - val_loss: 1.2290 - val_acc: 0.4633\n",
      "Epoch 53/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.7210\n",
      "Epoch 00053: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 100s 14ms/sample - loss: 0.3851 - acc: 0.7213 - val_loss: 1.2278 - val_acc: 0.4670\n",
      "Epoch 54/85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.7228\n",
      "Epoch 00054: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.3744 - acc: 0.7236 - val_loss: 1.3040 - val_acc: 0.4607\n",
      "Epoch 55/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3582 - acc: 0.7252\n",
      "Epoch 00055: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.3587 - acc: 0.7257 - val_loss: 1.2937 - val_acc: 0.6590\n",
      "Epoch 56/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3562 - acc: 0.7172\n",
      "Epoch 00056: val_acc did not improve from 0.66867\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.3567 - acc: 0.7166 - val_loss: 1.2904 - val_acc: 0.4690\n",
      "Epoch 57/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3235 - acc: 0.7060\n",
      "Epoch 00057: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.3233 - acc: 0.7066 - val_loss: 1.2606 - val_acc: 0.4663\n",
      "Epoch 58/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.7183\n",
      "Epoch 00058: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.3167 - acc: 0.7184 - val_loss: 1.2334 - val_acc: 0.4727\n",
      "Epoch 59/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3067 - acc: 0.7153\n",
      "Epoch 00059: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.3072 - acc: 0.7150 - val_loss: 1.2768 - val_acc: 0.4620\n",
      "Epoch 60/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.7474\n",
      "Epoch 00060: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 100s 14ms/sample - loss: 0.3066 - acc: 0.7480 - val_loss: 1.3141 - val_acc: 0.4643\n",
      "Epoch 61/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.3023 - acc: 0.7413\n",
      "Epoch 00061: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.3025 - acc: 0.7414 - val_loss: 1.3408 - val_acc: 0.4557\n",
      "Epoch 62/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2964 - acc: 0.7499\n",
      "Epoch 00062: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 100s 14ms/sample - loss: 0.2968 - acc: 0.7499 - val_loss: 1.3040 - val_acc: 0.4657\n",
      "Epoch 63/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2887 - acc: 0.7507\n",
      "Epoch 00063: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.2885 - acc: 0.7509 - val_loss: 1.3249 - val_acc: 0.4677\n",
      "Epoch 64/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2913 - acc: 0.7358\n",
      "Epoch 00064: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 101s 14ms/sample - loss: 0.2913 - acc: 0.7351 - val_loss: 1.3112 - val_acc: 0.4707\n",
      "Epoch 65/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.7400\n",
      "Epoch 00065: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2818 - acc: 0.7401 - val_loss: 1.3315 - val_acc: 0.4653\n",
      "Epoch 66/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.7431\n",
      "Epoch 00066: val_acc did not improve from 0.66867\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2745 - acc: 0.7434 - val_loss: 1.3104 - val_acc: 0.4703\n",
      "Epoch 67/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.7590\n",
      "Epoch 00067: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 0.2619 - acc: 0.7591 - val_loss: 1.3394 - val_acc: 0.6663\n",
      "Epoch 68/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.7520\n",
      "Epoch 00068: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2614 - acc: 0.7527 - val_loss: 1.3321 - val_acc: 0.6643\n",
      "Epoch 69/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2538 - acc: 0.7671\n",
      "Epoch 00069: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 0.2539 - acc: 0.7667 - val_loss: 1.3853 - val_acc: 0.4647\n",
      "Epoch 70/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2487 - acc: 0.7517\n",
      "Epoch 00070: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2493 - acc: 0.7514 - val_loss: 1.3495 - val_acc: 0.4650\n",
      "Epoch 71/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2472 - acc: 0.7630\n",
      "Epoch 00071: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2470 - acc: 0.7633 - val_loss: 1.3518 - val_acc: 0.4667\n",
      "Epoch 72/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.7698\n",
      "Epoch 00072: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.2440 - acc: 0.7696 - val_loss: 1.3674 - val_acc: 0.4693\n",
      "Epoch 73/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2395 - acc: 0.7520\n",
      "Epoch 00073: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 97s 14ms/sample - loss: 0.2394 - acc: 0.7523 - val_loss: 1.3683 - val_acc: 0.4580\n",
      "Epoch 74/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2417 - acc: 0.7648\n",
      "Epoch 00074: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2424 - acc: 0.7644 - val_loss: 1.3660 - val_acc: 0.4647\n",
      "Epoch 75/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.7622\n",
      "Epoch 00075: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 97s 14ms/sample - loss: 0.2432 - acc: 0.7621 - val_loss: 1.3689 - val_acc: 0.4670\n",
      "Epoch 76/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.7542\n",
      "Epoch 00076: val_acc did not improve from 0.66867\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2471 - acc: 0.7539 - val_loss: 1.3820 - val_acc: 0.4640\n",
      "Epoch 77/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2423 - acc: 0.7577\n",
      "Epoch 00077: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 99s 14ms/sample - loss: 0.2419 - acc: 0.7573 - val_loss: 1.3789 - val_acc: 0.4667\n",
      "Epoch 78/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.7726\n",
      "Epoch 00078: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2293 - acc: 0.7729 - val_loss: 1.3725 - val_acc: 0.4663\n",
      "Epoch 79/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.7659\n",
      "Epoch 00079: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2188 - acc: 0.7663 - val_loss: 1.4052 - val_acc: 0.4630\n",
      "Epoch 80/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.7586\n",
      "Epoch 00080: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2287 - acc: 0.7589 - val_loss: 1.3977 - val_acc: 0.4657\n",
      "Epoch 81/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.7529\n",
      "Epoch 00081: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 98s 14ms/sample - loss: 0.2261 - acc: 0.7523 - val_loss: 1.4083 - val_acc: 0.4663\n",
      "Epoch 82/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.7605\n",
      "Epoch 00082: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 94s 13ms/sample - loss: 0.2283 - acc: 0.7610 - val_loss: 1.3645 - val_acc: 0.4683\n",
      "Epoch 83/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.7457\n",
      "Epoch 00083: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 94s 13ms/sample - loss: 0.2215 - acc: 0.7457 - val_loss: 1.4166 - val_acc: 0.4650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.7534\n",
      "Epoch 00084: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 96s 14ms/sample - loss: 0.2234 - acc: 0.7533 - val_loss: 1.4419 - val_acc: 0.4600\n",
      "Epoch 85/85\n",
      "6976/7000 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.7603\n",
      "Epoch 00085: val_acc did not improve from 0.66867\n",
      "7000/7000 [==============================] - 95s 14ms/sample - loss: 0.2209 - acc: 0.7603 - val_loss: 1.4104 - val_acc: 0.4703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f9bfbd19d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(data, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
